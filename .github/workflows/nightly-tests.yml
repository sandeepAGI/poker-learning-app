name: Nightly Test Suite

on:
  schedule:
    - cron: '0 2 * * *'  # 2 AM UTC daily
  workflow_dispatch:      # Allow manual trigger

jobs:
  slow-backend-tests:
    name: Slow Backend Tests
    runs-on: ubuntu-latest
    timeout-minutes: 180

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          cd backend
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest-asyncio pytest-timeout requests

      - name: Run slow backend tests with crash detection
        run: |
          # Enable core dumps for segfault detection
          ulimit -c unlimited
          echo "Core dump limit: $(ulimit -c)"

          # Run tests with Python fault handler enabled
          PYTHONPATH=backend python -X faulthandler -m pytest backend/tests/ \
            -v --tb=long \
            -m "slow" \
            --timeout=600 \
            --ignore=backend/tests/test_bugs_real.py \
            --ignore=backend/tests/test_multiple_winners.py

          # Check for core dumps (segfaults)
          if compgen -G "core*" > /dev/null; then
            echo "::error::❌ Segmentation fault detected!"
            echo "Core dumps found:"
            ls -lh core* || true
            file core* || true
            echo "This indicates a crash in C extensions (likely treys library)"
            exit 1
          fi

          echo "✅ No segfaults detected"

      - name: Test Summary
        if: always()
        run: |
          echo "## Nightly Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Slow tests executed:**" >> $GITHUB_STEP_SUMMARY
          echo "- User scenarios: Multi-hand gameplay (19 min)" >> $GITHUB_STEP_SUMMARY
          echo "- Edge cases: 350+ scenarios" >> $GITHUB_STEP_SUMMARY
          echo "- Stress tests: 200-game AI marathon" >> $GITHUB_STEP_SUMMARY
          echo "- RNG fairness: Statistical validation" >> $GITHUB_STEP_SUMMARY
          echo "- Performance: Benchmarks" >> $GITHUB_STEP_SUMMARY
          echo "- Action fuzzing: Random action testing" >> $GITHUB_STEP_SUMMARY
          echo "- Concurrency: Multi-connection stress" >> $GITHUB_STEP_SUMMARY
          echo "- WebSocket simulation: Long-running scenarios" >> $GITHUB_STEP_SUMMARY

      - name: Upload results on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: nightly-test-results
          path: |
            htmlcov/
            pytest-results.xml
          retention-days: 7

      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Nightly Tests Failed (${new Date().toISOString().split('T')[0]})`,
              body: `## Nightly Test Failure\n\n**Workflow**: Nightly Test Suite\n**Run**: ${runUrl}\n**Date**: ${new Date().toISOString()}\n\n### Action Required\n\n1. Review logs: [View Run](${runUrl})\n2. Investigate failure cause\n3. Create fix or update this issue with findings\n4. Close issue when resolved\n\n### Investigation Checklist\n\n- [ ] Logs reviewed\n- [ ] Root cause identified\n- [ ] Fix implemented or issue documented\n- [ ] Verified fix in next nightly run\n\n### Test Categories\n\n- Stress tests (200-game AI marathon)\n- Performance benchmarks\n- RNG fairness (statistical)\n- Action fuzzing\n- Concurrency tests\n- Edge case scenarios (350+)\n- User scenarios (multi-hand)\n- WebSocket simulation`,
              labels: ['ci-failure', 'nightly', 'needs-investigation', 'automated']
            });

  slow-e2e-tests:
    name: Slow E2E Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install backend dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest-asyncio requests

      - name: Install frontend dependencies
        run: |
          cd frontend
          npm ci

      - name: Install Playwright browsers
        run: |
          cd frontend
          npx playwright install chromium

      - name: Start backend server
        run: |
          cd backend
          python main.py &
          sleep 5
        env:
          PYTHONUNBUFFERED: 1

      - name: Start frontend server
        run: |
          cd frontend
          npm run build
          npm run start &
          sleep 10
        env:
          NODE_ENV: production

      - name: Wait for servers to be ready
        run: |
          timeout 30 bash -c 'until curl -f http://localhost:8000/ > /dev/null 2>&1; do sleep 1; done'
          timeout 30 bash -c 'until curl -f http://localhost:3000/ > /dev/null 2>&1; do sleep 1; done'
          echo "✅ Both servers are ready"

      - name: Run visual regression tests
        run: |
          cd frontend
          npx playwright test ../tests/e2e/test_visual_regression.spec.ts --reporter=html
        env:
          FRONTEND_URL: http://localhost:3000
          BACKEND_URL: http://localhost:8000

      - name: Run full scenario tests
        run: |
          cd frontend
          npx playwright test ../tests/e2e/test_short_stack.spec.ts --reporter=html
        env:
          FRONTEND_URL: http://localhost:3000
          BACKEND_URL: http://localhost:8000

      - name: Upload Playwright report on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report-nightly
          path: playwright-report/
          retention-days: 7

      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Nightly E2E Tests Failed (${new Date().toISOString().split('T')[0]})`,
              body: `## Nightly E2E Test Failure\n\n**Workflow**: Nightly E2E Tests\n**Run**: ${runUrl}\n**Date**: ${new Date().toISOString()}\n\n### Action Required\n\n1. Review Playwright report (download artifacts)\n2. Check visual regression diffs\n3. Verify if intentional UI changes\n4. Update baselines or fix issues\n\n### Tests Included\n\n- Visual regression (pixel-perfect screenshot comparison)\n- Full game scenario tests\n- Long-running user flows`,
              labels: ['ci-failure', 'nightly', 'e2e', 'needs-investigation', 'automated']
            });
